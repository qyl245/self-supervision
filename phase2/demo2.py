import os
import torch
from torch.utils.data import DataLoader, Dataset
import random
from sliding_window import SlidingWindowDataset as SlidingWindowDatasetPhase1
from sklearn.preprocessing import LabelEncoder
from logging_utils import setup_logger

logger = setup_logger()

class SlidingWindowDatasetPhase2(SlidingWindowDatasetPhase1):
    """
    Phase2 ç‹¬ç«‹ç‰ˆ SlidingWindowDatasetï¼š
    ç”¨äºè·¨æ¨¡æ€ä»»åŠ¡ï¼Œå¼ºåˆ¶åŒæ¨¡æ€å­˜åœ¨
    """
    def __init__(self, *args, **kwargs):
        # ç¦ç”¨å•æ¨¡æ€è¿‡æ»¤é€»è¾‘
        kwargs['enable_filtering'] = False
        # å›ºå®šæˆå¤šæ¨¡æ€æ¨¡å¼
        kwargs['modality'] = None
        super().__init__(*args, **kwargs)

        # åœ¨åˆå§‹åŒ–ä¹‹åè¿‡æ»¤ preprocessed_trials
        self.preprocessed_trials = self._filter_dual_modality(self.preprocessed_trials)
        # é‡å»º window_indexï¼Œå› ä¸º trial æ•°é‡å˜åŒ–äº†
        self.window_index = self._build_window_index_from_cache()

    def _filter_dual_modality(self, trials):
        """åªä¿ç•™æ—¢æœ‰ emg_path åˆæœ‰ imu_path çš„ trial"""
        filtered = []
        for t in trials:
            if t.get('emg_path') and t.get('imu_path'):
                filtered.append(t)
        return filtered

    def __getitem__(self, idx):
        sample = super().__getitem__(idx)
        # Phase2å¿…é¡»åŒæ¨¡æ€
        if sample.get('emg') is None or sample.get('imu') is None:
            raise ValueError(f"[Phase2Dataset] ç´¢å¼• {idx} ç¼ºå¤±æ¨¡æ€")
        return sample



def build_label_encoder(dataset):
    """
    æ ¹æ®æ•´ä¸ª dataset çš„ activity_name æ„å»º LabelEncoder
    """
    all_labels = [sample['metadata']['activity_name'] for sample in dataset]
    le = LabelEncoder()
    le.fit(all_labels)
    return le


# ====== æ•°æ®å¢å¼ºå‡½æ•° ======
def augment_emg(emg_tensor):
    """
    emg_tensor: (C, T) å•æ ·æœ¬ æˆ– (B, C, T) æ‰¹é‡
    """
    x = emg_tensor.clone()

    # 1. é«˜æ–¯å™ªå£°æ‰°åŠ¨
    if random.random() > 0.5:
        x += torch.randn_like(x) * 0.05

    # 2. æ—¶é—´æ©ç 
    if random.random() > 0.5:
        # é’ˆå¯¹æ¯ä¸ªé€šé“åšéšæœºæ©ç 
        mask = torch.rand_like(x[..., :1]) > 0.2
        x = x * mask

    # 3. é€šé“ä¸¢å¼ƒ
    if random.random() > 0.3:
        drop_idx = random.randint(0, x.shape[-2] - 1)  # Cç»´
        if x.dim() == 2:       # (C, T)
            x[drop_idx] = 0
        elif x.dim() == 3:     # (B, C, T)
            x[:, drop_idx] = 0

    # 4. æ—¶é—´ç¼©æ”¾ (ä¿®å¤çº¿æ€§æ¨¡å¼4Dé”™è¯¯)
    if random.random() > 0.3:
        scale = random.uniform(0.8, 1.2)
        T = x.shape[-1]
        new_T = max(1, int(T * scale))

        if x.dim() == 2:  # (C, T) å•æ ·æœ¬
            x = torch.nn.functional.interpolate(
                x.unsqueeze(0), size=new_T, mode='linear', align_corners=False
            ).squeeze(0)
        elif x.dim() == 3:  # (B, C, T) æ‰¹é‡
            out_batch = []
            for sample in x:
                sample_scaled = torch.nn.functional.interpolate(
                    sample.unsqueeze(0), size=new_T, mode='linear', align_corners=False
                ).squeeze(0)
                out_batch.append(sample_scaled)
            x = torch.stack(out_batch, dim=0)

        # ä¿æŒåŸé•¿åº¦T
        if new_T < T:
            pad_len = T - new_T
            pad_shape = list(x.shape[:-1]) + [pad_len]
            x = torch.cat([x, torch.zeros(*pad_shape, device=x.device)], dim=-1)
        elif new_T > T:
            x = x[..., :T]

    # 5. é¢‘åŸŸæ‰°åŠ¨
    if random.random() > 0.3:
        freq = torch.fft.rfft(x, dim=-1)
        noise = (torch.randn_like(freq) + 1j * torch.randn_like(freq)) * 0.02
        freq = freq + noise
        x = torch.fft.irfft(freq, n=x.shape[-1], dim=-1)

    return x


def augment_imu(imu_tensor):
    """
    imu_tensor: (S, C, T) ä¸å¸¦ batch, æˆ– (B, S, C, T)
    """
    x = imu_tensor.clone()

    # 1. é«˜æ–¯å™ªå£°æ‰°åŠ¨
    if random.random() > 0.5:
        x += torch.randn_like(x) * 0.05

    # 2. æ—¶é—´æ©ç 
    if random.random() > 0.5:
        mask = torch.rand_like(x[..., :1]) > 0.2
        x = x * mask

    # 3. ä¼ æ„Ÿå™¨ä¸¢å¼ƒ
    if random.random() > 0.3:
        drop_sensor = random.randint(0, x.shape[0] - 1)
        x[drop_sensor] = 0

    # 4. æ—¶é—´ç¼©æ”¾ (ä¿®å¤4Dè¾“å…¥é—®é¢˜)
    if random.random() > 0.3:
        scale = random.uniform(0.85, 1.15)
        T = x.shape[-1]
        new_T = max(1, int(T * scale))

        if x.dim() == 3:  # (S, C, T)
            out = []
            for sensor in x:
                # sensor: (C, T) -> æ’å€¼è¦æ±‚(N, C, L)
                sensor_scaled = torch.nn.functional.interpolate(
                    sensor.unsqueeze(0), size=new_T, mode='linear', align_corners=False
                ).squeeze(0)
                out.append(sensor_scaled)
            x = torch.stack(out, dim=0)
        elif x.dim() == 4:  # (B, S, C, T)
            out_batch = []
            for sample in x:
                out_sensors = []
                for sensor in sample:
                    sensor_scaled = torch.nn.functional.interpolate(
                        sensor.unsqueeze(0), size=new_T, mode='linear', align_corners=False
                    ).squeeze(0)
                    out_sensors.append(sensor_scaled)
                out_batch.append(torch.stack(out_sensors, dim=0))
            x = torch.stack(out_batch, dim=0)

        # å°ºå¯¸å¯¹é½å›åŸT
        if new_T < T:
            pad_len = T - new_T
            pad_shape = list(x.shape[:-1]) + [pad_len]
            x = torch.cat([x, torch.zeros(*pad_shape, device=x.device)], dim=-1)
        elif new_T > T:
            x = x[..., :T]

    # 5. é¢‘åŸŸæ‰°åŠ¨
    if random.random() > 0.3:
        freq = torch.fft.rfft(x, dim=-1)
        noise = (torch.randn_like(freq) + 1j * torch.randn_like(freq)) * 0.02
        freq = freq + noise
        x = torch.fft.irfft(freq, n=x.shape[-1], dim=-1)

    return x


# ====== Phase 2 Transform ======
def phase2_transform(sample):
    """ç¡®ä¿åŒæ¨¡æ€æ•°æ®åœ¨å¢å¼ºå‰å­˜åœ¨"""
    if sample['emg'] is None or sample['imu'] is None:
        raise ValueError("[phase2_transform] è¾“å…¥æ ·æœ¬ç¼ºæ¨¡æ€ï¼")

    emg = augment_emg(sample['emg'])
    imu = augment_imu(sample['imu'])

    meta = sample['metadata']
    meta['trial_id'] = str(meta['trial_id'])
    meta['window_index'] = int(meta['window_index'])

    return {
        'emg': emg,
        'imu': imu,
        'metadata': meta
    }


class Phase2Dataset(Dataset):
    def __init__(self, base_dataset):
        self.base_dataset = base_dataset

    def __len__(self):
        return len(self.base_dataset)

    def __getitem__(self, idx):
        sample = self.base_dataset[idx]
        return phase2_transform(sample)


def make_collate_fn(le):
    def collate_fn(batch):
        batch_out = {
            'emg': torch.stack([item['emg'] for item in batch]),
            'imu': torch.stack([item['imu'] for item in batch]),
            'metadata': [item['metadata'] for item in batch],
            'labels': torch.tensor(
                le.transform([item['metadata']['activity_name'] for item in batch]),
                dtype=torch.long
            )
        }
        return batch_out
    return collate_fn


def build_phase2_loaders(config, base_datasets):
    data_cfg = config['data']

    # SlidingWindowDataset è¯·ç”¨ä½ åŸæ¥çš„å®šä¹‰
    full_dataset = SlidingWindowDatasetPhase2(
        base_datasets=base_datasets,
        window_sec=data_cfg['window_sec'],
        step_sec=data_cfg['step_sec'],
        target_sr=data_cfg['target_sr'],
        cache_dir=data_cfg['cache_dir'],
        enable_filtering=data_cfg['enable_filtering'],
        config=config,
        num_jobs=data_cfg.get('num_jobs', 20),
        force_rebuild=False
    )


    # ===== Step 3: ç¨€æœ‰åŠ¨ä½œè¿‡æ»¤ï¼ˆæ–¹æ³•1ï¼‰ =====
    min_subj_per_act = data_cfg.get('min_subjects_per_action', None)
    rare_actions = set()
    if min_subj_per_act is not None:
        from collections import defaultdict
        # ç»Ÿè®¡æ¯ä¸ªåŠ¨ä½œçš„å—è¯•è€…é›†åˆ
        subjects_per_action = defaultdict(set)
        for win in full_dataset.window_index:
            act = str(win['metadata']['activity_name'])
            sid = str(win['metadata']['subject_id'])
            subjects_per_action[act].add(sid)

        rare_actions = {act for act, subj_set in subjects_per_action.items()
                        if len(subj_set) < min_subj_per_act}
        if rare_actions:
            logger.info(f"[FILTER] Removing rare actions with subjects < {min_subj_per_act}: {sorted(rare_actions)}")
        else:
            logger.info("[FILTER] No rare actions found.")

    # ===== Step 4: æ•°æ®é›†åˆ’åˆ† =====
    if data_cfg.get('subject_split_path') and os.path.exists(data_cfg['subject_split_path']):
        split = torch.load(data_cfg['subject_split_path'])
        train_subjects = set(split['train_subjects'])
        val_subjects = set(split['val_subjects'])
        logger.info("ğŸ“‚ Loaded subject split from file, ensuring consistent train/val subjects.")

    else:
        seed = config.get("seed", 42)
        torch.manual_seed(seed)

        # è·å–æ‰€æœ‰ unique subject_id
        all_subjects = list({win['metadata']['subject_id'] for win in full_dataset.window_index})
        logger.info(f"ğŸ“Š Total unique subjects: {len(all_subjects)}")

        # éšæœºæ‰“ä¹±å—è¯•è€…é¡ºåº
        if isinstance(all_subjects[0], str):
            import random
            random.Random(seed).shuffle(all_subjects)
        else:
            all_subjects = torch.tensor(all_subjects)
            all_subjects = all_subjects[torch.randperm(len(all_subjects))].tolist()

        train_subject_count = int(0.8 * len(all_subjects))
        train_subjects = set(all_subjects[:train_subject_count])
        val_subjects = set(all_subjects[train_subject_count:])

        # ä¿å­˜åˆ’åˆ†
        torch.save({
            'train_subjects': list(train_subjects),
            'val_subjects': list(val_subjects)
        }, data_cfg.get('subject_split_path'))

    # æ ¹æ® subject è¿‡æ»¤ + ç¨€æœ‰åŠ¨ä½œè¿‡æ»¤çª—å£ç´¢å¼•
    train_indices = [
        i for i, win in enumerate(full_dataset.window_index)
        if win['metadata']['subject_id'] in train_subjects
           and (str(win['metadata']['activity_name']) not in rare_actions)
    ]
    val_indices = [
        i for i, win in enumerate(full_dataset.window_index)
        if win['metadata']['subject_id'] in val_subjects
           and (str(win['metadata']['activity_name']) not in rare_actions)
    ]

    logger.info(f"ğŸ“Š Train samples(after filter): {len(train_indices)}, Val samples(after filter): {len(val_indices)}")

    # ===== è°ƒè¯•æ—¥å¿— - æ£€æŸ¥äº¤å‰å—è¯•è€… =====
    overlap_subjects = train_subjects & val_subjects
    if overlap_subjects:
        logger.warning(
            f"âš ï¸ æ•°æ®æ³„éœ²é£é™©: {len(overlap_subjects)}ä¸ªå—è¯•è€…åœ¨ Train å’Œ Val é›†éƒ½æœ‰å‡ºç°: {overlap_subjects}")
    else:
        logger.info("âœ… æ— å—è¯•è€…äº¤å‰ï¼Œæ•°æ®åˆ’åˆ†å®‰å…¨ã€‚")



    train_ds = Phase2Dataset(torch.utils.data.Subset(full_dataset, train_indices))
    val_ds = Phase2Dataset(torch.utils.data.Subset(full_dataset, val_indices))


    le = build_label_encoder(val_ds)

    collate_fn_train = make_collate_fn(le)
    collate_fn_val = make_collate_fn(le)

    worker_count = min(data_cfg.get('num_workers', 12), os.cpu_count())
    prefetch_factor = data_cfg.get('prefetch_factor', 4)

    train_loader = DataLoader(
        train_ds,
        batch_size=data_cfg['batch_size'],
        shuffle=True,
        num_workers=worker_count,
        pin_memory=True,
        persistent_workers=True,
        prefetch_factor=prefetch_factor,
        drop_last=True,
        collate_fn=collate_fn_train
    )

    val_loader = DataLoader(
        val_ds,
        batch_size=data_cfg['batch_size'],
        shuffle=False,
        num_workers=worker_count,
        pin_memory=True,
        persistent_workers=True,
        prefetch_factor=prefetch_factor,
        drop_last=False,
        collate_fn=collate_fn_val
    )

    return train_loader, val_loader, le
